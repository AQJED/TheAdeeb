<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Low Latency in Simulation Middleware | The Solo Developer</title>
    <style>
        :root {
            --bg-color: #0f172a;
            --card-bg: #1e293b;
            --text-main: #e2e8f0;
            --text-muted: #94a3b8;
            --accent: #10b981;
            --accent-hover: #34d399;
            --font-mono: 'Courier New', Courier, monospace;
            --font-sans: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }

        * { box-sizing: border-box; margin: 0; padding: 0; }

        body {
            background-color: var(--bg-color);
            color: var(--text-main);
            font-family: var(--font-sans);
            line-height: 1.8;
        }

        .container { max-width: 800px; margin: 0 auto; padding: 0 20px; }

        header { padding: 20px 0; border-bottom: 1px solid #334155; margin-bottom: 60px; }
        nav { display: flex; justify-content: space-between; align-items: center; }
        .logo { font-family: var(--font-mono); font-weight: bold; font-size: 1.2rem; color: var(--accent); }
        .back-link { font-size: 0.9rem; color: var(--text-muted); text-decoration: none; }

        article h1 { font-size: 2.5rem; margin-bottom: 10px; line-height: 1.2; }
        .meta { color: var(--text-muted); font-family: var(--font-mono); font-size: 0.85rem; margin-bottom: 40px; display: block; }
        
        article h3 { 
            color: var(--accent); 
            font-family: var(--font-mono); 
            margin-top: 40px; 
            margin-bottom: 15px; 
            font-size: 1.4rem; 
        }

        article p { margin-bottom: 20px; font-size: 1.1rem; color: #cbd5e1; }
        strong { color: white; }

        ul { margin-bottom: 20px; padding-left: 20px; }
        li { margin-bottom: 10px; color: #cbd5e1; font-size: 1.1rem; }

        footer {
            text-align: center;
            padding: 60px 0;
            color: var(--text-muted);
            font-size: 0.9rem;
            border-top: 1px solid #334155;
            margin-top: 80px;
        }
    </style>
</head>
<body>

    <header>
        <div class="container">
            <nav>
                <div class="logo">&lt;Solo_Dev /&gt;</div>
                <a href="index.html" class="back-link">← Back to Logs</a>
            </nav>
        </div>
    </header>

    <div class="container">
        <article>
            <span class="meta">TAGS: LATENCY // REAL-TIME // PERFORMANCE</span>
            <h1>Low Latency in Simulation Middleware: Practical Lessons</h1>
            
            <p>
                In flight simulation, latency shows up as a physical mismatch between the pilot's input and the system's response (visuals or motion). If these signals don't align, the simulator feels out of sync even if the frame rate is high. I’ve spent a lot of time building middleware to translate packets between different protocols, and I've found that performance usually comes down to predictability rather than raw speed. I mean, keeping the processing time consistent is more important than how fast the code runs on average.
            </p>

            <h3>Latency vs. Jitter</h3>
            
            <p>
                We often focus on raw latency, but jitter is actually the bigger problem. A pilot can adapt to a consistent 20ms lag. They cannot adapt to a lag that fluctuates between 10ms and 50ms. When building middleware, the goal is to make the processing time as deterministic as possible. However, a middleware with latency larger than 1ms is considered slow.
            </p>

            <h3>Categorizing the delay</h3>
            <p>
                I usually split delay into two areas:
            </p>
            <ul>
                <li><strong>Network/OS delay:</strong> Time lost before the application receives the packet (kernel buffering, driver overhead, etc.). You have limited control here outside of OS tuning.</li>
                <li><strong>Application delay:</strong> Time spent inside your code. This includes parsing, coordinate conversion math, and thread synchronization. This is where you can adjust your code to avoid lag.</li>
            </ul>

            <h3>Reducing memory movement</h3>
            
            <p>
                It is very easy to accidentally move data too much. A common pattern I see is: receive a UDP buffer, copy it into a struct, pass it to a function that copies it into a class, then copy it again into an output buffer.
            </p>
            <p>
                Every memcpy adds a small amount of time, but more importantly, It causes the timing to fluctuate when the system is busy. In my middleware, I try to process data in place or use a single, pre-allocated buffer for the entire pipeline to keep memory movement at a minimum.
            </p>

            <h3>Selective parsing</h3>
            <p>
                You don't always need to decode the entire packet. If you're receiving a massive CIGI or DIS state update but only need the ownship position, decoding the entire payload is a waste of CPU. It is like skimming the title and first two lines of a letter just to verify what it is, instead of reading the whole thing.
            </p>
            <p>
                I found that adding "early exit" rules like checking the packet ID and dropping it before the parsing logic even starts, significantly stabilized the CPU load. If you don't need a packet, you should touch it for the shortest time possible.
            </p>

            <h3>Avoiding allocations in the time-sensitive path</h3>
            <p>
                Calling new or malloc (or using containers like std::vector that might resize) inside your main loop is a major source of jitter. Most of the time, allocations are fast. Occasionally, the allocator has to perform a search or reclaim memory, which creates a random timing spike. Using fixed-size, pre-allocated buffers is a boring but effective way to remove this variable.
            </p>

            <h3>Handling backlog and outdated data</h3>
            
            <p>
                This is a specific problem for real-time systems. If you get a spike of traffic and your system can't keep up, a queue builds up.
            </p>
            <p>
                If you try to process every single packet in that queue, you end up forwarding "old" state. Even when the traffic spike ends, your middleware might still be lagging behind the "real-time" state because it's working through the backlog. For simulation, it is almost always better to drop old packets and jump to the latest state than it is to process every update in order.
            </p>

            <h3>Compromises in real-time design</h3>
            <p>
                There is no pure win. Every gain comes with a cost:
            </p>
            <ul>
                <li><strong>CPU vs. Latency:</strong> You can lower receiving delay by having a thread "spin" (busy-wait) so it catches a packet the moment it hits the NIC. This lowers latency but keeps a CPU core at 100%, which can cause scheduling issues for other threads on the same machine.</li>
                <li><strong>Capacity vs. Timing:</strong> Batching packets improves the total number of messages you can handle per second, but it ruins timing. It forces the first packet in the batch to wait for the last one. In flight sims, consistent spacing is usually more important than total Capacity.</li>
                <li><strong>Reliability:</strong> You have to decide which data is disposable. A position update can be dropped because a new one is coming in 10 ms. A control command (landing gear toggle) cannot be dropped because it might be sent once. Separating these into different handling paths is essential.</li>
            </ul>

            <h3>Summary of what worked</h3>
            <ul>
                <li>Measure the worst-case (p99), not the average. Averages hide the spikes that pilots actually feel.</li>
                <li>Filter early. Check the port or the message ID before doing any heavy lifting.</li>
                <li>Keep it predictable. Your code should do the exact same amount of work every time a packet arrives. If one path through your code is significantly "heavier" than another, you’ve just created a source of jitter.</li>
            </ul>

        </article>
    </div>

    <footer>
        <div class="container">
            <p>Built by Adeeb. Code. Crash. Learn. Repeat.</p>
        </div>
    </footer>

</body>
</html>
